{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txx2RJPQyS0e"
   },
   "source": [
    "Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DrcmPM3sTD7g"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "31SzhOBHTisg",
    "outputId": "208e0c4a-7c72-466a-e41f-720d6af50bec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L5MwGHdoTwBt"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "l5qTuHOkT5Kb",
    "outputId": "b6c6f3aa-64e9-4422-cd88-7b4959a8335c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CWcU1dxgiXT"
   },
   "source": [
    "Performing oversampling by applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Qf_tApU4eoLb"
   },
   "outputs": [],
   "source": [
    "x_res=df.iloc[:, df.columns!= 'Class']\n",
    "y_res=df.iloc[:,df.columns=='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ErqbkjCwiivR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\rachi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\rachi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\rachi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rachi\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nCJ-lGk1ilfZ"
   },
   "outputs": [],
   "source": [
    "sample=SMOTE()\n",
    "x_res,y_res=sample.fit_resample(x_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "HZhd2O5GiudX",
    "outputId": "a090a5e3-d389-4bbe-a35a-39d20ed161ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>136</td>\n",
       "      <td>0.260504</td>\n",
       "      <td>0.503396</td>\n",
       "      <td>0.404165</td>\n",
       "      <td>0.170678</td>\n",
       "      <td>0.695373</td>\n",
       "      <td>0.195657</td>\n",
       "      <td>0.233592</td>\n",
       "      <td>0.130401</td>\n",
       "      <td>-0.145185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>-0.144981</td>\n",
       "      <td>-0.424863</td>\n",
       "      <td>0.142697</td>\n",
       "      <td>-1.192719</td>\n",
       "      <td>-1.128851</td>\n",
       "      <td>0.083854</td>\n",
       "      <td>0.191495</td>\n",
       "      <td>0.194145</td>\n",
       "      <td>1.274266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>433</td>\n",
       "      <td>-1.723186</td>\n",
       "      <td>1.690095</td>\n",
       "      <td>-1.293583</td>\n",
       "      <td>3.452207</td>\n",
       "      <td>-0.495063</td>\n",
       "      <td>-1.367300</td>\n",
       "      <td>-2.103164</td>\n",
       "      <td>1.127334</td>\n",
       "      <td>-2.310640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093797</td>\n",
       "      <td>0.384558</td>\n",
       "      <td>-0.164675</td>\n",
       "      <td>-0.367387</td>\n",
       "      <td>0.323982</td>\n",
       "      <td>0.073658</td>\n",
       "      <td>0.164071</td>\n",
       "      <td>0.214395</td>\n",
       "      <td>-0.114530</td>\n",
       "      <td>0.212850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>237</td>\n",
       "      <td>-0.655522</td>\n",
       "      <td>0.979132</td>\n",
       "      <td>-0.178127</td>\n",
       "      <td>1.301495</td>\n",
       "      <td>0.411907</td>\n",
       "      <td>-0.261283</td>\n",
       "      <td>-0.569592</td>\n",
       "      <td>0.522126</td>\n",
       "      <td>-0.931920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.068641</td>\n",
       "      <td>-0.275933</td>\n",
       "      <td>-0.037291</td>\n",
       "      <td>-0.849328</td>\n",
       "      <td>-0.951007</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>0.240732</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>0.687480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>401</td>\n",
       "      <td>-1.278821</td>\n",
       "      <td>-1.435338</td>\n",
       "      <td>1.765866</td>\n",
       "      <td>0.783336</td>\n",
       "      <td>1.891638</td>\n",
       "      <td>0.474979</td>\n",
       "      <td>-1.272753</td>\n",
       "      <td>0.562556</td>\n",
       "      <td>0.582337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389551</td>\n",
       "      <td>0.230638</td>\n",
       "      <td>0.646506</td>\n",
       "      <td>0.246743</td>\n",
       "      <td>-1.033486</td>\n",
       "      <td>-0.626382</td>\n",
       "      <td>0.587638</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>-0.031437</td>\n",
       "      <td>1.322527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>224</td>\n",
       "      <td>-0.524606</td>\n",
       "      <td>0.902254</td>\n",
       "      <td>-0.064989</td>\n",
       "      <td>1.088420</td>\n",
       "      <td>0.485720</td>\n",
       "      <td>-0.169202</td>\n",
       "      <td>-0.414093</td>\n",
       "      <td>0.453414</td>\n",
       "      <td>-0.786664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.033192</td>\n",
       "      <td>-0.294969</td>\n",
       "      <td>-0.003476</td>\n",
       "      <td>-0.941746</td>\n",
       "      <td>-1.029675</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.239119</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.741806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   136  0.260504  0.503396  0.404165  0.170678  0.695373  0.195657   \n",
       "1522   433 -1.723186  1.690095 -1.293583  3.452207 -0.495063 -1.367300   \n",
       "1523   237 -0.655522  0.979132 -0.178127  1.301495  0.411907 -0.261283   \n",
       "1524   401 -1.278821 -1.435338  1.765866  0.783336  1.891638  0.474979   \n",
       "1525   224 -0.524606  0.902254 -0.064989  1.088420  0.485720 -0.169202   \n",
       "\n",
       "            V7        V8        V9  ...       V20       V21       V22  \\\n",
       "0     0.239599  0.098698  0.363787  ...  0.251412 -0.018307  0.277838   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.524980  0.247998  0.771679   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274   \n",
       "4     0.592941 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521  0.233592  0.130401 -0.145185  ... -0.048127 -0.144981 -0.424863   \n",
       "1522 -2.103164  1.127334 -2.310640  ...  0.093797  0.384558 -0.164675   \n",
       "1523 -0.569592  0.522126 -0.931920  ...  0.008282  0.068641 -0.275933   \n",
       "1524 -1.272753  0.562556  0.582337  ...  0.389551  0.230638  0.646506   \n",
       "1525 -0.414093  0.453414 -0.786664  ... -0.001092  0.033192 -0.294969   \n",
       "\n",
       "           V23       V24       V25       V26       V27       V28      Amount  \n",
       "0    -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000  \n",
       "1     0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000  \n",
       "2     0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000  \n",
       "3    -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000  \n",
       "4    -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000  \n",
       "...        ...       ...       ...       ...       ...       ...         ...  \n",
       "1521  0.142697 -1.192719 -1.128851  0.083854  0.191495  0.194145    1.274266  \n",
       "1522 -0.367387  0.323982  0.073658  0.164071  0.214395 -0.114530    0.212850  \n",
       "1523 -0.037291 -0.849328 -0.951007  0.106712  0.240732  0.116055    0.687480  \n",
       "1524  0.246743 -1.033486 -0.626382  0.587638 -0.000610 -0.031437    1.322527  \n",
       "1525 -0.003476 -0.941746 -1.029675  0.101091  0.239119  0.136548    0.741806  \n",
       "\n",
       "[1526 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "huACzugmkJWx"
   },
   "outputs": [],
   "source": [
    "x_res['Class']=y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "aDZg3-DJkQF9",
    "outputId": "18481ea3-3883-4525-efdc-f09e39f29ad1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>136</td>\n",
       "      <td>0.260504</td>\n",
       "      <td>0.503396</td>\n",
       "      <td>0.404165</td>\n",
       "      <td>0.170678</td>\n",
       "      <td>0.695373</td>\n",
       "      <td>0.195657</td>\n",
       "      <td>0.233592</td>\n",
       "      <td>0.130401</td>\n",
       "      <td>-0.145185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144981</td>\n",
       "      <td>-0.424863</td>\n",
       "      <td>0.142697</td>\n",
       "      <td>-1.192719</td>\n",
       "      <td>-1.128851</td>\n",
       "      <td>0.083854</td>\n",
       "      <td>0.191495</td>\n",
       "      <td>0.194145</td>\n",
       "      <td>1.274266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>433</td>\n",
       "      <td>-1.723186</td>\n",
       "      <td>1.690095</td>\n",
       "      <td>-1.293583</td>\n",
       "      <td>3.452207</td>\n",
       "      <td>-0.495063</td>\n",
       "      <td>-1.367300</td>\n",
       "      <td>-2.103164</td>\n",
       "      <td>1.127334</td>\n",
       "      <td>-2.310640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384558</td>\n",
       "      <td>-0.164675</td>\n",
       "      <td>-0.367387</td>\n",
       "      <td>0.323982</td>\n",
       "      <td>0.073658</td>\n",
       "      <td>0.164071</td>\n",
       "      <td>0.214395</td>\n",
       "      <td>-0.114530</td>\n",
       "      <td>0.212850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>237</td>\n",
       "      <td>-0.655522</td>\n",
       "      <td>0.979132</td>\n",
       "      <td>-0.178127</td>\n",
       "      <td>1.301495</td>\n",
       "      <td>0.411907</td>\n",
       "      <td>-0.261283</td>\n",
       "      <td>-0.569592</td>\n",
       "      <td>0.522126</td>\n",
       "      <td>-0.931920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068641</td>\n",
       "      <td>-0.275933</td>\n",
       "      <td>-0.037291</td>\n",
       "      <td>-0.849328</td>\n",
       "      <td>-0.951007</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>0.240732</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>0.687480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>401</td>\n",
       "      <td>-1.278821</td>\n",
       "      <td>-1.435338</td>\n",
       "      <td>1.765866</td>\n",
       "      <td>0.783336</td>\n",
       "      <td>1.891638</td>\n",
       "      <td>0.474979</td>\n",
       "      <td>-1.272753</td>\n",
       "      <td>0.562556</td>\n",
       "      <td>0.582337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230638</td>\n",
       "      <td>0.646506</td>\n",
       "      <td>0.246743</td>\n",
       "      <td>-1.033486</td>\n",
       "      <td>-0.626382</td>\n",
       "      <td>0.587638</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>-0.031437</td>\n",
       "      <td>1.322527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>224</td>\n",
       "      <td>-0.524606</td>\n",
       "      <td>0.902254</td>\n",
       "      <td>-0.064989</td>\n",
       "      <td>1.088420</td>\n",
       "      <td>0.485720</td>\n",
       "      <td>-0.169202</td>\n",
       "      <td>-0.414093</td>\n",
       "      <td>0.453414</td>\n",
       "      <td>-0.786664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033192</td>\n",
       "      <td>-0.294969</td>\n",
       "      <td>-0.003476</td>\n",
       "      <td>-0.941746</td>\n",
       "      <td>-1.029675</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.239119</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.741806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   136  0.260504  0.503396  0.404165  0.170678  0.695373  0.195657   \n",
       "1522   433 -1.723186  1.690095 -1.293583  3.452207 -0.495063 -1.367300   \n",
       "1523   237 -0.655522  0.979132 -0.178127  1.301495  0.411907 -0.261283   \n",
       "1524   401 -1.278821 -1.435338  1.765866  0.783336  1.891638  0.474979   \n",
       "1525   224 -0.524606  0.902254 -0.064989  1.088420  0.485720 -0.169202   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521  0.233592  0.130401 -0.145185  ... -0.144981 -0.424863  0.142697   \n",
       "1522 -2.103164  1.127334 -2.310640  ...  0.384558 -0.164675 -0.367387   \n",
       "1523 -0.569592  0.522126 -0.931920  ...  0.068641 -0.275933 -0.037291   \n",
       "1524 -1.272753  0.562556  0.582337  ...  0.230638  0.646506  0.246743   \n",
       "1525 -0.414093  0.453414 -0.786664  ...  0.033192 -0.294969 -0.003476   \n",
       "\n",
       "           V24       V25       V26       V27       V28      Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000      0  \n",
       "...        ...       ...       ...       ...       ...         ...    ...  \n",
       "1521 -1.192719 -1.128851  0.083854  0.191495  0.194145    1.274266      1  \n",
       "1522  0.323982  0.073658  0.164071  0.214395 -0.114530    0.212850      1  \n",
       "1523 -0.849328 -0.951007  0.106712  0.240732  0.116055    0.687480      1  \n",
       "1524 -1.033486 -0.626382  0.587638 -0.000610 -0.031437    1.322527      1  \n",
       "1525 -0.941746 -1.029675  0.101091  0.239119  0.136548    0.741806      1  \n",
       "\n",
       "[1526 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juMOFnETzHAV"
   },
   "source": [
    "RANDOM SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DEqna4hojALt"
   },
   "outputs": [],
   "source": [
    "sample_df=x_res.sample(1067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pOopwoqmo4dP"
   },
   "outputs": [],
   "source": [
    "x=sample_df.iloc[:, sample_df.columns!= 'Class']\n",
    "y=sample_df.iloc[:,sample_df.columns=='Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmhG-skFgndc"
   },
   "source": [
    "Splitting the data in test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9A20j0t_fFCM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r3M1rWFgrde"
   },
   "source": [
    "Using Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzfIxfYwfyuf",
    "outputId": "b8e00d35-5504-40da-faf3-eb86ecb0c95f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbpy7MIDf7pr",
    "outputId": "aa6ade66-fc3d-4b5e-db91-96533f03435e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0\n",
      " 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0\n",
      " 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred  =  classifier.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qa5XEaj8gCem",
    "outputId": "89303900-c253-4068-9e04-40fdcef6491c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8878504672897196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3pyYbYRWgwjL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BBHkqZLzNVK"
   },
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9Vvro2jn3Le",
    "outputId": "fcaf13b0-5909-4d3c-bc2b-79e9615b3d4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\AppData\\Local\\Temp\\ipykernel_20852\\3758756570.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfC4TGB2oB_b",
    "outputId": "17295848-846c-45f4-af93-a5a73fc100c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0\n",
      " 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1\n",
      " 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred2  =  rf.predict(x_test)\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8kNLxbNoGu8",
    "outputId": "7dbca602-08fb-49b5-8b22-d74efb2fcece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906542056074766\n"
     ]
    }
   ],
   "source": [
    "score2=accuracy_score(y_pred2,y_test)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Wc_fsBRzU9w"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQ5SaPkHp3iO",
    "outputId": "d73db501-1cfc-4985-ee2d-2218175c440b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(x_train, y_train)\n",
    "logr_pred = logr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4o3BMi5p8BA",
    "outputId": "ba6d86da-f0d5-4a48-d624-fec357cd3e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9392523364485982\n"
     ]
    }
   ],
   "source": [
    "score3=accuracy_score(logr_pred,y_test)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzfrB0Nh0oXZ"
   },
   "source": [
    "Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WfftpjL9qG7d"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "y_pred3 = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Wp6LwtAsAW7",
    "outputId": "3d34dba7-8c2f-4a23-9d5a-e85bca5dfa15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9813084112149533\n"
     ]
    }
   ],
   "source": [
    "score4=accuracy_score(y_pred3,y_test)\n",
    "print(score4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUvD8yKh0sgG"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iq47DC4ismgr",
    "outputId": "a4851d7d-fdcb-4d8d-a77d-c58af1691d2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:200: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "aMuBts1dssf5"
   },
   "outputs": [],
   "source": [
    "pred4=knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWDdwReItD2m",
    "outputId": "736fd77c-8f67-4499-9650-c10f97657889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8084112149532711\n"
     ]
    }
   ],
   "source": [
    "score5=accuracy_score(pred4,y_test)\n",
    "print(score5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FCumYAh0vMs"
   },
   "source": [
    "Storing all accuracies in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGV27yZLv3y6",
    "outputId": "6cce28e9-c097-43d3-9c52-4fcf206febed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8878504672897196,\n",
       " 0.9906542056074766,\n",
       " 0.9392523364485982,\n",
       " 0.9813084112149533,\n",
       " 0.8084112149532711]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_sampling=[score,score2,score3,score4,score5]\n",
    "simple_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c-hj2xGMY1e"
   },
   "source": [
    "STRATIFIED SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7s0CAaDEwXAc"
   },
   "outputs": [],
   "source": [
    "strat=x_res.groupby('Class', group_keys=False).apply(lambda x: x.sample(392,replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UN-qYuL_xPR5"
   },
   "outputs": [],
   "source": [
    "x=strat.iloc[:, strat.columns!= 'Class']\n",
    "y=strat.iloc[:,strat.columns=='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fuNOLnhXxTJm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOHS2D-Nx984"
   },
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0245YS0xkGj",
    "outputId": "aff17025-4f2d-4225-d061-dee5cb243ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8407643312101911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred6  =  classifier.predict(x_test)\n",
    "score6=accuracy_score(y_pred6,y_test)\n",
    "print(score6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltHjQyrQyAAX"
   },
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccSBpWz8yCv6",
    "outputId": "d1c4c1e6-d03f-4c2e-80b8-a1a808b27266"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\AppData\\Local\\Temp\\ipykernel_20852\\1374587416.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred7  =  rf.predict(x_test)\n",
    "score7=accuracy_score(y_pred7,y_test)\n",
    "print(score7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kccgSBLDMdBu"
   },
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hV4nH2GBy5SH",
    "outputId": "407be019-6149-4184-fa24-67c53241efea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9490445859872612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(x_train, y_train)\n",
    "pred8 = logr.predict(x_test)\n",
    "score8=accuracy_score(pred8,y_test)\n",
    "print(score8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt43xuJgMfSq"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8CbyrrozNyF",
    "outputId": "112d780b-baaf-4543-b839-2390e008569e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808917197452229\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "y_pred9 = clf.predict(x_test)\n",
    "score9=accuracy_score(y_pred9,y_test)\n",
    "print(score9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkhqM8dBMiS_"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlXJkQqNzhSC",
    "outputId": "9985c53d-129e-4b07-dcd2-530b12cd270f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7707006369426752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:200: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(x_train, y_train)\n",
    "pred10=knn.predict(x_test)\n",
    "score10=accuracy_score(pred10,y_test)\n",
    "print(score10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X76zwEDCzzBK",
    "outputId": "f229c76a-53d2-4931-cefb-90f586a1ba56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8407643312101911,\n",
       " 1.0,\n",
       " 0.9490445859872612,\n",
       " 0.9808917197452229,\n",
       " 0.7707006369426752]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_sampling=[score6,score7,score8,score9,score10]\n",
    "stratified_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9MRTxWzMk9Y"
   },
   "source": [
    "SYSTEMATIC SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dAjsMZKbOgRh"
   },
   "outputs": [],
   "source": [
    "def systematic_sampling(df, step):\n",
    "    indexes = np.arange(0, len(df), step=step)\n",
    "    systematic_sample = df.iloc[indexes]\n",
    "    return systematic_sample\n",
    "data = systematic_sampling(x_res, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "tZwgDX5rPE88"
   },
   "outputs": [],
   "source": [
    "x = data.iloc[:,data.columns!='Class']\n",
    "y = data.iloc[:,data.columns=='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "IqL-KEEuPU_o"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZyRO6KIPlHF"
   },
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwDhlgggPgii",
    "outputId": "0ef7efbd-09f4-4dec-a759-53f1dad4ab2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8300653594771242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred11  =  classifier.predict(x_test)\n",
    "score11=accuracy_score(y_pred11,y_test)\n",
    "print(score11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RGjlbehP0Fc"
   },
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0vQ26ebPriz",
    "outputId": "a6d32eb8-a2b4-4e2e-8a38-6017b23c3b28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\AppData\\Local\\Temp\\ipykernel_20852\\2019656218.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9934640522875817\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred12  =  rf.predict(x_test)\n",
    "score12=accuracy_score(y_pred12,y_test)\n",
    "print(score12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YeXzlXxQIEa"
   },
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8HsdNE4P2A6",
    "outputId": "9f9dcab0-a4c2-47fb-bfc1-89b3e0fc79d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(x_train, y_train)\n",
    "pred13 = logr.predict(x_test)\n",
    "score13=accuracy_score(pred13,y_test)\n",
    "print(score13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBwXs-7yQKhZ"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkyXTf_VQNKs",
    "outputId": "bc1ea989-8436-4e01-9068-cbbab1795945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "y_pred14 = clf.predict(x_test)\n",
    "score14=accuracy_score(y_pred14,y_test)\n",
    "print(score14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNu9ioVjQUdM"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWCF091zQVI-",
    "outputId": "e517b511-109b-4f48-fcc8-a7592b21a937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8300653594771242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:200: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(x_train, y_train)\n",
    "pred15=knn.predict(x_test)\n",
    "score15=accuracy_score(pred15,y_test)\n",
    "print(score15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_AW9omLRAOF",
    "outputId": "b1503d77-a5da-4641-c19c-1d28ba409d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8300653594771242,\n",
       " 0.9934640522875817,\n",
       " 0.8823529411764706,\n",
       " 0.9607843137254902,\n",
       " 0.8300653594771242]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "systematic_sampling=[score11,score12,score13,score14,score15]\n",
    "systematic_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSdS8EsCUTl9"
   },
   "source": [
    "CLUSTER SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "hTiM_MsiRK_6",
    "outputId": "6a124087-de60-440f-a275-3304ea034b42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>564</td>\n",
       "      <td>0.186118</td>\n",
       "      <td>-0.159358</td>\n",
       "      <td>-1.389222</td>\n",
       "      <td>-2.433996</td>\n",
       "      <td>1.753378</td>\n",
       "      <td>3.593082</td>\n",
       "      <td>-1.582165</td>\n",
       "      <td>-1.903514</td>\n",
       "      <td>-1.314805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>-0.139815</td>\n",
       "      <td>1.036164</td>\n",
       "      <td>0.804413</td>\n",
       "      <td>-0.242090</td>\n",
       "      <td>0.103552</td>\n",
       "      <td>0.276180</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.997176</td>\n",
       "      <td>0.228365</td>\n",
       "      <td>1.715340</td>\n",
       "      <td>-0.420067</td>\n",
       "      <td>0.560838</td>\n",
       "      <td>0.564725</td>\n",
       "      <td>0.846047</td>\n",
       "      <td>0.197491</td>\n",
       "      <td>-0.097202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.072651</td>\n",
       "      <td>-0.272272</td>\n",
       "      <td>-0.087682</td>\n",
       "      <td>0.138132</td>\n",
       "      <td>0.125902</td>\n",
       "      <td>-0.063022</td>\n",
       "      <td>86.430000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>524</td>\n",
       "      <td>-0.292211</td>\n",
       "      <td>0.838605</td>\n",
       "      <td>1.360847</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>0.350836</td>\n",
       "      <td>-0.894645</td>\n",
       "      <td>1.382872</td>\n",
       "      <td>-0.431655</td>\n",
       "      <td>-0.400719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368186</td>\n",
       "      <td>-0.150624</td>\n",
       "      <td>0.391048</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>-0.571952</td>\n",
       "      <td>-0.135755</td>\n",
       "      <td>-0.176200</td>\n",
       "      <td>52.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>222</td>\n",
       "      <td>-0.352704</td>\n",
       "      <td>0.975517</td>\n",
       "      <td>1.603365</td>\n",
       "      <td>-0.282475</td>\n",
       "      <td>0.480561</td>\n",
       "      <td>-0.222647</td>\n",
       "      <td>0.850194</td>\n",
       "      <td>-0.265018</td>\n",
       "      <td>-0.283460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062304</td>\n",
       "      <td>-0.231531</td>\n",
       "      <td>-0.412572</td>\n",
       "      <td>-0.180927</td>\n",
       "      <td>0.201127</td>\n",
       "      <td>0.178832</td>\n",
       "      <td>-0.034650</td>\n",
       "      <td>7.810000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>459</td>\n",
       "      <td>-2.176450</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.166329</td>\n",
       "      <td>2.752858</td>\n",
       "      <td>0.777903</td>\n",
       "      <td>-0.546163</td>\n",
       "      <td>-2.351272</td>\n",
       "      <td>1.128820</td>\n",
       "      <td>-1.145563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501004</td>\n",
       "      <td>-0.132783</td>\n",
       "      <td>-0.192704</td>\n",
       "      <td>-0.070425</td>\n",
       "      <td>0.475473</td>\n",
       "      <td>0.093082</td>\n",
       "      <td>-0.155380</td>\n",
       "      <td>0.653488</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>379</td>\n",
       "      <td>-0.812518</td>\n",
       "      <td>-1.456953</td>\n",
       "      <td>1.677181</td>\n",
       "      <td>0.976948</td>\n",
       "      <td>1.427965</td>\n",
       "      <td>-0.013184</td>\n",
       "      <td>-1.308427</td>\n",
       "      <td>0.426627</td>\n",
       "      <td>0.621732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.235887</td>\n",
       "      <td>-0.420445</td>\n",
       "      <td>-0.060477</td>\n",
       "      <td>0.581361</td>\n",
       "      <td>-0.087666</td>\n",
       "      <td>-0.097360</td>\n",
       "      <td>1.934276</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>29</td>\n",
       "      <td>0.996370</td>\n",
       "      <td>-0.122589</td>\n",
       "      <td>0.546819</td>\n",
       "      <td>0.706580</td>\n",
       "      <td>0.134560</td>\n",
       "      <td>1.156995</td>\n",
       "      <td>-0.294561</td>\n",
       "      <td>0.407429</td>\n",
       "      <td>0.337863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108867</td>\n",
       "      <td>0.162231</td>\n",
       "      <td>-0.575624</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.373813</td>\n",
       "      <td>0.050552</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>20.530000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>244</td>\n",
       "      <td>-1.118946</td>\n",
       "      <td>-0.071366</td>\n",
       "      <td>2.807769</td>\n",
       "      <td>1.025675</td>\n",
       "      <td>-0.100748</td>\n",
       "      <td>0.508680</td>\n",
       "      <td>0.620313</td>\n",
       "      <td>-0.213137</td>\n",
       "      <td>0.333039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455553</td>\n",
       "      <td>0.170942</td>\n",
       "      <td>0.076211</td>\n",
       "      <td>0.197637</td>\n",
       "      <td>-0.286674</td>\n",
       "      <td>-0.230530</td>\n",
       "      <td>-0.405084</td>\n",
       "      <td>100.370000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>135</td>\n",
       "      <td>1.207207</td>\n",
       "      <td>0.241318</td>\n",
       "      <td>0.258745</td>\n",
       "      <td>0.653335</td>\n",
       "      <td>-0.256426</td>\n",
       "      <td>-0.620309</td>\n",
       "      <td>-0.039653</td>\n",
       "      <td>-0.022139</td>\n",
       "      <td>0.145191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780158</td>\n",
       "      <td>0.165657</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.116176</td>\n",
       "      <td>0.126406</td>\n",
       "      <td>-0.012156</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>339</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>0.930065</td>\n",
       "      <td>-0.857525</td>\n",
       "      <td>2.042940</td>\n",
       "      <td>-1.505946</td>\n",
       "      <td>-1.000185</td>\n",
       "      <td>-1.991363</td>\n",
       "      <td>0.460577</td>\n",
       "      <td>-1.124101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062191</td>\n",
       "      <td>-0.012187</td>\n",
       "      <td>0.479788</td>\n",
       "      <td>0.531947</td>\n",
       "      <td>-0.441323</td>\n",
       "      <td>0.460792</td>\n",
       "      <td>0.219985</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "754    564  0.186118 -0.159358 -1.389222 -2.433996  1.753378  3.593082   \n",
       "118     76 -0.997176  0.228365  1.715340 -0.420067  0.560838  0.564725   \n",
       "694    524 -0.292211  0.838605  1.360847 -0.001346  0.350836 -0.894645   \n",
       "308    222 -0.352704  0.975517  1.603365 -0.282475  0.480561 -0.222647   \n",
       "1130   459 -2.176450  0.014411  0.166329  2.752858  0.777903 -0.546163   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1287   379 -0.812518 -1.456953  1.677181  0.976948  1.427965 -0.013184   \n",
       "38      29  0.996370 -0.122589  0.546819  0.706580  0.134560  1.156995   \n",
       "333    244 -1.118946 -0.071366  2.807769  1.025675 -0.100748  0.508680   \n",
       "203    135  1.207207  0.241318  0.258745  0.653335 -0.256426 -0.620309   \n",
       "460    339  0.503302  0.930065 -0.857525  2.042940 -1.505946 -1.000185   \n",
       "\n",
       "            V7        V8        V9  ...       V22       V23       V24  \\\n",
       "754  -1.582165 -1.903514 -1.314805  ...  0.656716 -0.139815  1.036164   \n",
       "118   0.846047  0.197491 -0.097202  ...  0.015445  0.072651 -0.272272   \n",
       "694   1.382872 -0.431655 -0.400719  ...  0.368186 -0.150624  0.391048   \n",
       "308   0.850194 -0.265018 -0.283460  ... -0.062304 -0.231531 -0.412572   \n",
       "1130 -2.351272  1.128820 -1.145563  ...  0.501004 -0.132783 -0.192704   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1287 -1.308427  0.426627  0.621732  ...  0.455272  0.235887 -0.420445   \n",
       "38   -0.294561  0.407429  0.337863  ...  0.108867  0.162231 -0.575624   \n",
       "333   0.620313 -0.213137  0.333039  ...  0.455553  0.170942  0.076211   \n",
       "203  -0.039653 -0.022139  0.145191  ... -0.780158  0.165657  0.012956   \n",
       "460  -1.991363  0.460577 -1.124101  ... -0.062191 -0.012187  0.479788   \n",
       "\n",
       "           V25       V26       V27       V28      Amount  Class  cluster  \n",
       "754   0.804413 -0.242090  0.103552  0.276180   48.000000      0        2  \n",
       "118  -0.087682  0.138132  0.125902 -0.063022   86.430000      0        2  \n",
       "694   0.186411 -0.571952 -0.135755 -0.176200   52.050000      0        2  \n",
       "308  -0.180927  0.201127  0.178832 -0.034650    7.810000      0        2  \n",
       "1130 -0.070425  0.475473  0.093082 -0.155380    0.653488      1        2  \n",
       "...        ...       ...       ...       ...         ...    ...      ...  \n",
       "1287 -0.060477  0.581361 -0.087666 -0.097360    1.934276      1       11  \n",
       "38    0.109795  0.373813  0.050552  0.005106   20.530000      0       11  \n",
       "333   0.197637 -0.286674 -0.230530 -0.405084  100.370000      0       11  \n",
       "203   0.116176  0.126406 -0.012156  0.026239    4.570000      0       11  \n",
       "460   0.531947 -0.441323  0.460792  0.219985    2.000000      0       11  \n",
       "\n",
       "[654 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clustered_Sample(df, n_per_cluster, num_select_clusters):\n",
    "    N = len(df)\n",
    "    K = int(N/n_per_cluster)\n",
    "    data = None\n",
    "    for k in range(K):\n",
    "        sample_k = df.sample(n_per_cluster)\n",
    "        sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
    "        df = df.drop(index = sample_k.index)\n",
    "        data = pd.concat([data,sample_k],axis = 0)\n",
    "    random_chosen_clusters = np.random.randint(0,K,size = num_select_clusters)\n",
    "    samples = data[data.cluster.isin(random_chosen_clusters)]\n",
    "    return(samples)\n",
    "cluster_data = get_clustered_Sample(df = x_res, n_per_cluster = 109, num_select_clusters = 7)\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oq1056_VU6dC"
   },
   "outputs": [],
   "source": [
    "x = cluster_data.iloc[:,cluster_data.columns!='Class']\n",
    "y = cluster_data.iloc[:,cluster_data.columns=='Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "D3etMeK_Xdxo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DkS2RUEXpvK"
   },
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehtfo1R2XrMk",
    "outputId": "4a1fdeee-2e36-4c41-d6f5-fae3e07180df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549618320610687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred16  =  classifier.predict(x_test)\n",
    "score16=accuracy_score(y_pred16,y_test)\n",
    "print(score16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpLMQfNvXyeb"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmPVFO7iX0Lu",
    "outputId": "0138fc7e-869e-4d46-99e3-04e35b8bf597"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\AppData\\Local\\Temp\\ipykernel_20852\\3083300405.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923664122137404\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred17  =  rf.predict(x_test)\n",
    "score17=accuracy_score(y_pred17,y_test)\n",
    "print(score17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLVxDjiHYIl1"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YF9l1UiXYXPr",
    "outputId": "0db6284c-3371-423e-97db-326ed8047f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916030534351145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(x_train, y_train)\n",
    "pred18 = logr.predict(x_test)\n",
    "score18=accuracy_score(pred18,y_test)\n",
    "print(score18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE62v4IfYdoV"
   },
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0DW6KfwYg-L",
    "outputId": "29eb1bfc-6dce-479c-eeb0-ecc2684714a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541984732824428\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "y_pred19 = clf.predict(x_test)\n",
    "score19=accuracy_score(y_pred19,y_test)\n",
    "print(score19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6dULhOsYpSu"
   },
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBnkBws0YqSe",
    "outputId": "e71a9f92-80fb-4b63-ad29-178f37c8ca37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938931297709924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:200: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(x_train, y_train)\n",
    "pred20=knn.predict(x_test)\n",
    "score20=accuracy_score(pred20,y_test)\n",
    "print(score20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OeaxVttY1s2",
    "outputId": "0d1a9df2-53ba-407a-ec76-e5b6827e0367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8549618320610687,\n",
       " 0.9923664122137404,\n",
       " 0.916030534351145,\n",
       " 0.9541984732824428,\n",
       " 0.7938931297709924]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sampling=[score16,score17,score18,score19,score20]\n",
    "cluster_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-jPe1kwwBJu"
   },
   "source": [
    "Comibining all the calculated accuracies of different sampling techniques in a single table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "mRBN0sKgZAtC"
   },
   "outputs": [],
   "source": [
    "df2=pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "aVgxn_1x7yy9"
   },
   "outputs": [],
   "source": [
    "model=['Naive Bayes','Random Forest','Logistic Regression','Decision Tree classifier','KNN']\n",
    "finaltable= {\n",
    "    'Models': model,\n",
    "    'Simple random':simple_sampling,\n",
    "    'Stratified' :stratified_sampling,\n",
    "    'Systematic': systematic_sampling,\n",
    "    'Cluster':cluster_sampling\n",
    "          }\n",
    "df2 = pd.DataFrame(finaltable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WFta-SHv8aZ0",
    "outputId": "e2647728-0838-4ba5-fe40-620f43109577"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Simple random</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Systematic</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.887850</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.830065</td>\n",
       "      <td>0.854962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.992366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.939252</td>\n",
       "      <td>0.949045</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.916031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree classifier</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.954198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.770701</td>\n",
       "      <td>0.830065</td>\n",
       "      <td>0.793893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models  Simple random  Stratified  Systematic   Cluster\n",
       "0               Naive Bayes       0.887850    0.840764    0.830065  0.854962\n",
       "1             Random Forest       0.990654    1.000000    0.993464  0.992366\n",
       "2       Logistic Regression       0.939252    0.949045    0.882353  0.916031\n",
       "3  Decision Tree classifier       0.981308    0.980892    0.960784  0.954198\n",
       "4                       KNN       0.808411    0.770701    0.830065  0.793893"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8_BwPwyJjCc"
   },
   "source": [
    "From the above table we can conclude that Random forest shows maximum accuracy with all the above sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
